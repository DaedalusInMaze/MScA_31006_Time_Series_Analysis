---
title: "HW5_TS"
author: "Curtis Zhuang"
date: "2021/5/2"
output: html_document
---


```{r setup, include=FALSE, warning = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```

```{r, echo = FALSE, warning = FALSE, include = FALSE}
library(tseries)
library(fpp)
library(TSA)
library(forecast)
library(ggplot2)
```

<br>

#### **Question 1:**
#### Load the condmilk.rda dataset and split it into a training dataset (1971/1 â€“ 1979/12) and a test dataset (1980/1 â€“ 1980/12)
```{r}
load('condmilk.rda')

## Split
train <- condmilk[1:108]
test <- condmilk[109:120]

## Convert to ts
train_milk <- ts(train, start = c(1971, 1), frequency = 12)
test_milk <- ts(test, start = c(1980, 1), frequency = 12)
```

<br>


#### **Question 2:**
#### Plot the training dataset. Is Box-Cox transformation necessary for this data?

```{r}
tsdisplay(train_milk)

### From the graph we see that variance change overtime so we do need transformations
lambda <- BoxCox.lambda(train_milk)
lambda

# do transformation based on the best lambda 
tran_milk <- BoxCox(train_milk, lambda = lambda)

tsdisplay(tran_milk)
```

**By looking at the ts plot, we see that the variance is flucutaing from year to year so we need to do a transformation. And we performed boxcox based on the auto lambda value.**

<br>


#### **Question 3:**
#### Is the training dataset stationary? If not, find an appropriate differencing which yields seasonal and trend stationary training dataset. Plot the ACF and PACF to determine if the detrended and deseasonalized time series is stationary.

```{r}
tsdisplay(diff(tran_milk, lag = 12))

qqnorm(diff(tran_milk), pch = 1, frame = FALSE)
qqline(diff(tran_milk), col = "steelblue", lwd = 2)

# Adf test
adf.test(diff(tran_milk))


## KPSS test
kpss.test(diff(tran_milk), null = c("Level", "Trend"), lshort = TRUE)
```

**When looking at the ACF and PACF at original data, we see that the residual is not stationary. So I took a first order difference with lag 12 and then look at the PACF and ACF. From QQ plot we see that the residual is much better. I also performed Adf and KPSS test for first order difference and both tell me it is stationary now. **


<br>


#### **Question 4:**
#### Build two ğ´ğ‘…ğ¼ğ‘€ğ´(ğ‘,ğ‘‘,ğ‘)(ğ‘ƒ,ğ‘„,ğ·)ğ‘  models using the training dataset and auto.arima() function.
â€¢ Model 1: Let the auto.arima() function determine the best order of non-seasonal and seasonal differencing.

Report the resulting ğ‘,ğ‘‘,ğ‘,ğ‘ƒ,ğ·,ğ‘„,ğ‘  and the coefficients values for all cases and compare their AICc and BIC values.

```{r}
model_1 <- auto.arima(train_milk, lambda = 'auto', seasonal = TRUE, trace = TRUE)

model_1
```
**For model 1, p = 1, d = 0, q = 0, P = 2, D = 1, Q = 0, s = 12. All the coefficients are listed above and AICc = -410.37 and BIC = -400.55.**


<br>

â€¢ Model 2: Set the order of seasonal-differencing ğ‘‘ to 1 and ğ· to 1.
```{r}
model_2 <- auto.arima(train_milk, lambda = 'auto', seasonal = TRUE, trace = TRUE, D = 1, d = 1)

model_2
```
**For model 2, p = 1, d = 1, q = 1, P = 2, D = 1, Q = 0, s = 12. All the coefficients are listed and AICc = -399.58 and BIC = -387.49.**

<br>


#### **Question 5:**
#### Plot the residuals ACF of both models from part 4 and use the Ljung-Box Test with lag 12 to verify your conclusion.

```{r}
checkresiduals(model_1)

checkresiduals(model_2)

shapiro.test(model_1$residuals)

shapiro.test(model_2$residuals)
```
**From Shapiro-Wilk test, we see that both has p < 0.05 which we can then reject our null hypothesis that residual is normal. From Ljung-Box test both have p value on border so we will use the result from S-W test and it is not normally distributed.**


<br>


#### **Question 6:**
#### Use both models from part 4 and the h-period argument in the forecast() function to forecast each month of 1980 (i.e., Jan, Feb, â€¦, Dec.) Plot the test dataset and forecasted values.

```{r}
h <- 12

### Model 1

model_forecast_1 <-forecast(model_1, h)

model_forecast_1

plot(model_forecast_1)

### Model 2

model_forecast_2 <-forecast(model_2, h)

model_forecast_2

plot(model_forecast_2)

```

<br>


#### **Question 7:**
#### Compare the forecast with the actual test data by calculating the Mean Absolute Percentage Error (MAPE) and Mean Squared Error (MSE). Which model is better to forecast the Manufacturer's Stocks for each month of 1980 (i.e., Jan, Feb, â€¦, Dec)?

```{r}
MSE_1 <- sum((model_forecast_1$mean - test_milk)^2) / 12

MSE_1

MAPE_1 <- sum(abs((test_milk - model_forecast_1$mean) / model_forecast_1$mean))/12

MAPE_1

accuracy(model_forecast_1, test_milk)
```
**For model 1, the MSE is equal to 303.4648 and MAPE equal to 0.1868 from calculation. The MAPE value is a little bit different if we use the value from the accuracy function and it will be 0.1847. This may be caused by the difference in calculation method and is not a big issue.**


```{r}
# Model 2

MSE_2 <- sum((model_forecast_2$mean - test_milk)^2) / 12

MSE_2

MAPE_2 <- sum(abs((test_milk - model_forecast_2$mean) / model_forecast_2$mean))/12

MAPE_2

accuracy(model_forecast_2, test_milk)
```
**For model 2, MSE is equal to 303.4596 and MAPE is equal to 0.1882 or 0.1851 for the two methods.**

<br>


#### **Question 8:**
#### Forecast each month of 1980 (i.e., Jan, Feb, â€¦, Dec.) using the seasonal naÃ¯ve forecast method. Plot the test dataset and forecasted values, and compare the forecast with the actual test data by calculating the Mean Absolute Percentage Error (MAPE) and Mean Squared Error (MSE).

```{r}
model_SNaive <- snaive(train_milk, h)

MSE_S <- sum((model_SNaive$mean - test)^2) / 12

MSE_S

MAPE_S <- sum(abs((test - model_SNaive$mean) / model_SNaive$mean))/12

MAPE_S

accuracy(model_SNaive, test_milk)
```
**For the model using seasonal naive method, MSE is equal to 277.8286 and MAPE is equal to 0.1900.**


















